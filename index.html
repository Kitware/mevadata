---
layout: page
title: Mevadata
permalink: /
---

<!-- Slider Start -->
<section id="slider">
  <div class="container">
    <div class="row">
      <div class="block">
        <h1 class="animated fadeInUp">The Multivew Extended Video with Events (MEVA) dataset</h1>
        <p class="animated fadeInUp"> The large-scale MEVA dataset is designed for activity
          detection in multi-camera environments. It was created on the Intelligence Advanced
          Research Projects Activity (IARPA) Deep Intermodal Video Analytics (DIVA) program 
          to support DIVA performers and the broader research community.</p>
      </div>
    </div>
  </div>
</section>
<!-- Wrapper Start -->
<section id="intro">
  <div class="container">
    <div class="row">
      <div class="col-md-7 col-sm-12">
        <div class="block">
          <div class="section-title">
            <h2>About MEVA data</h2>
            <p>The current known-facility data release features approximately 185 hours of activity-
              rich data.</p>
          </div>
          <h3>Releases</h3>
          <p><strong>Known Facility Release:</strong> This data was collected at the Muscatatuck Urban Training Center
            with a team of over 100 actors performing in various scenarios. The fields of view, both
            overlapping and non-overlapping, capture person and vehicle activities in indoor and outdoor
            environments. There were multiple realistic scenarios with a variety of scripted and
            non-scripted activities, including scripted threat activities such as abandoning
            packages and theft.</p>
          <p>The camera infrastructure included commercial-off-the-shelf EO cameras; thermal
            infrared cameras as part of several IR-EO pairs; 4K video data from multiple UAVs; and
            a range of still images from handheld cameras.</p>
          <p>Additional resources such as a facility site map, camera model information, and camera
            calibration models will be also be released.</p>
          <p>The videos provide a sample of the outdoor MEVA data. A packet of sample videos can be downloaded
            from [ADD DOWNLOAD LINK HERE].</p>
        </div>
      </div><!-- .col-md-7 close -->
      <div class="col-md-5 col-sm-12">
        <div class="block">
          <video controls width="100%" style="margin: 32px 0 20px;">
            <source src="video/2018-03-07.16-55-00.17-00-00.bus.G340.recoded.mp4" type="video/mp4">
            Sorry, your browser doesn't support embedded videos.
          </video>

          <video controls width="100%" style="margin: 0 0 20px;">
            <source src="video/2018-03-07.17-20-00.17-25-00.school.G336.recoded.mp4" type="video/mp4">
            Sorry, your browser doesn't support embedded videos.
          </video>
        </div>
      </div><!-- .col-md-5 close -->
    </div>
  </div>
</section>

<section id="feature">
<div class="container">
  <div class="row">
    <div class="col-md-6 col-md-offset-6">
      <h2>ACCESSING AND USING MEVA</h2>
      <p>MEVA data is available for use under a CC BY-4.0 license (full license text available). Sample videos
        are provided [DOWNLOADA LINK HERE]. The full corpus of data is available for download via an Amazon Web Services
      requester-pays paradigm. The full-scale videos in the download are approximately [SIZE OF DATA HERE]. </p>
      <p>The <a href="#">README</A> details the directory structure and organization of the data available on AWS.</p>
      <a href="#" class="button-primary">Download Example Videos</a>
    </div>
  </div>
</div>
</section>

<section id="service">
  <div class="container">
    <div class="row">
      <div class="section-title">
        <h2>Annotating MEVA</h2>
        <p>The MEVA data can be annotated using your preferred annotation toolchain. For annotating
          and using the MEVA data for the DIVA program, the following steps are recommended:</p>
      </div>
    </div>
    <div class="row ">
      <div class="col-sm-6 col-md-4">
        <div class="service-item">
          <i class="ion-checkmark-circled"></i>
          <h4>Download data</h4>
          <p>The full dataset is accessible through an Amazon Web
            Services download. An AWS account will be required.</p>
            <a href="#" class="button-primary">Download Data</a>
        </div>
      </div>
      <div class="col-sm-6 col-md-4">
        <div class="service-item">
          <i class="ion-code-download"></i>
          <h4>Review Annotation Guidelines</h4>
          <p>Download the current DIVA activity definitions. These should guide which activities
            and objects are annotated. (available only to DIVA performers)</p>
          <a href="#" class="button-primary">Download</a>
        </div>
      </div>
      <div class="col-sm-6 col-md-4">
        <div class="service-item">
          <i class="ion-qr-scanner"></i>
          <h4>Generate annotations</h4>
          <p>Generate annotations that meet the following requirements which are part of the T&E
            json file formats <strong>(comma separated list of file formats here)</strong></p>
        </div>
      </div>
    <div class="row ">
          <p>Kitware’s Vp-View tool can be downloaded [ADD DOWNLOAD LINK] and used to create annotations for the 
            DIVA program. There is a document that outlines how to use Vp-View for DIVA annotations. 
            Note that the annotations being created for the T&E effort on DIVA 
            do not include full tracks; individuals, vehicles, or objects are only annotated during the 
            execution of an activity. See the DIVA Annotation Guidelines [ADD LINL] for a chart of track 
            requirements per activity type.</p>
      </div>
    </div>
  </div>
</section>

{% comment %}
<!-- CALL TO ACTION START
<section id="call-to-action">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <div class="block">
          <h2>We design delightful digital experiences.</h2>
          <p>Read more about what we do and our philosophy of design. Judge for yourself The work and results we’ve achieved for other clients, and meet our highly experienced Team who just love to design.</p>
          <a class="btn btn-default btn-call-to-action" href="#" >Tell Us Your Story</a>
        </div>
      </div>
    </div>
  </div>
</section> CALL TO ACTION END -->

<!-- CONTENT START
<section id="testimonial">
  <div class="container">
    <div class="row">
      <div class="section-title text-center">
        <h2>Fun Facts About Us</h2>
        <p>Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics</p>
      </div>
    </div>
    <div class="row">
      <div class="col-md-6">
        {% if site.data.funfacts.size > 0 %}
        <div class="block">
          {% for ff in site.data.funfacts %}
          <ul class="counter-box clearfix">
            <li>
              <div class="block">
                <i class="{{ ff.icon }}"></i>
                <h4 class="counter">{{ ff.counter }}</h4>
                <span>{{ ff.text }}</span>
              </div>
            </li>
            {% endfor %}
          </ul>
        </div>
        {% endif %}
      </div>
      <div class="col-md-6">
        {% if site.data.testimonials.size > 0 %}
        <div class="testimonial-carousel">
          <div id="testimonial-slider" class="owl-carousel">
            {% for tm in site.data.testimonials %}
            <div>
                <img src="img/cotation.png" alt="IMG">
                <p>{{ tm.testimonial }}</p>
                <div class="user">
                  <img src="{{ tm.image }}" alt="Pepole">
                  <p><span>{{ tm.name }}</span> {{ tm.title }}</p>
                </div>
            </div>
            {% endfor %}
          </div>
        </div>
        {% endif %}
      </div>
    </div>
  </div>
</section> CONTENT END-->
{% endcomment %}
